{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root mean squared error = 1.42546810271799\n",
      "root mean squared error = 1.4372115060100445\n",
      "root mean squared error = 1.4235326121107466\n",
      "root mean squared error = 1.4192025120327854\n",
      "root mean squared error = 1.4243339973355145\n",
      "root mean squared error = 1.4191067066340588\n",
      "root mean squared error = 1.4246518854623114\n",
      "root mean squared error = 1.433292647449805\n",
      "root mean squared error = 1.4166308644955734\n",
      "root mean squared error = 1.4373431347986392\n",
      "root mean squared error = 1.4308574692675007\n",
      "root mean squared error = 1.440334811022058\n",
      "root mean squared error = 1.4220925520712246\n",
      "root mean squared error = 1.437775168170913\n",
      "root mean squared error = 1.4235410021036747\n",
      "root mean squared error = 1.4159226918524566\n",
      "root mean squared error = 1.4100082725069558\n",
      "root mean squared error = 1.4120581179923648\n",
      "root mean squared error = 1.4380521063669487\n",
      "root mean squared error = 1.4462892336889581\n",
      "root mean squared error = 1.428607191962204\n",
      "root mean squared error = 1.4369655506456904\n",
      "root mean squared error = 1.4158615662882426\n",
      "root mean squared error = 1.4205955476721939\n",
      "root mean squared error = 1.4280300948627838\n",
      "root mean squared error = 1.4045994086562552\n",
      "root mean squared error = 1.4113028860081072\n",
      "root mean squared error = 1.4167292055206688\n",
      "root mean squared error = 1.4202276408911914\n",
      "root mean squared error = 1.408702095319042\n",
      "root mean squared error = 1.4193058461728942\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "#chr8,chr18 as test set\n",
    "def sequence_file(tile_num):\n",
    "    #create datapaths \n",
    "    Data_path = \"/u/home/m/mardren/scratch/SequenceML\"\n",
    "    gkm_path = \"%s/features.gkSVM.HepG2.tsv.gz\"%Data_path\n",
    "    conv_path       = \"%s/features.dragoNN_ConvModel.HepG2.SV40P.Rep1.tsv.gz\"%Data_path\n",
    "    deepfact_path       = \"%s/features.dragoNN_DeepFactorizedModel.HepG2.SV40P.Rep1.tsv.gz\"%Data_path\n",
    "    #this is the label, sorry kind of confusingly named\n",
    "    sharpr_path = \"%s/6mer_sharpr_score_tile_evenchrtesting.pkl\"%Data_path\n",
    "\n",
    "\n",
    "    #open data from csv into dataframes\n",
    "    gkm = pd.read_csv(gkm_path, header = 0, index_col = 0, sep = '\\t')\n",
    "    conv  = pd.read_csv(conv_path, header = 0, index_col = 0, sep = '\\t')\n",
    "    deepfact = pd.read_csv(deepfact_path, header = 0, index_col = 0, sep = '\\t')\n",
    "    #subset by selected tile\n",
    "    sharpr = pd.read_pickle('%s'%(sharpr_path))\n",
    "    gkm_15 = gkm[['feat_gksvm_%s'%tile_num]]\n",
    "    gkm_15 = gkm_15.rename(columns = {'feat_gksvm_%s'%tile_num:'gkm_%s'%tile_num})\n",
    "    conv_15 = conv[[tile_num]]\n",
    "    conv_15 = conv_15.rename(columns = {tile_num:'conv_%s'%tile_num})\n",
    "    deepfact_15 = deepfact[[tile_num]]\n",
    "    deepfact_15 = deepfact_15.rename(columns = {tile_num:'deepfact_%s'%tile_num})\n",
    "    tile_num = int(tile_num)\n",
    "    sharpr_15 = sharpr[[tile_num]]\n",
    "    sharpr_15 = sharpr_15.rename(columns = {tile_num:'sharpr_%s'%tile_num})\n",
    "\n",
    "    #create data dataframe\n",
    "    data = pd.concat([conv_15,gkm_15,deepfact_15, sharpr_15], axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #reset index to be able to access region_id\n",
    "    data = data.reset_index()\n",
    "\n",
    "    #split region_id to create chrom column\n",
    "    data['chrom'] = data['region_id'].str.split('_').str[3]\n",
    "\n",
    "    #splitting training testing data\n",
    "    #     train_chroms = [f'chr{i}' for i in range(1,23,2)]\n",
    "    #     test_chroms = [f'chr{i}' for i in range(2,23,2)]\n",
    "    #     chrX = data[data[\"chrom\"]==('chrX')]\n",
    "    #     test_set = data[data[\"chrom\"].isin(test_chroms)]\n",
    "    #     train_set = data[data[\"chrom\"].isin(train_chroms)]\n",
    "    #     train_set = train_set.append(chrX)\n",
    "    test_set_8 = data[data[\"chrom\"] == ('chr8')]\n",
    "    test_set_18 = data[data[\"chrom\"] ==('chr18')]\n",
    "    test_set = pd.concat([test_set_8,test_set_18],axis=0)\n",
    "    train_set = data[data[\"chrom\"] != ('chr8')]\n",
    "    train_set = train_set[train_set[\"chrom\"] != ('chr18')]\n",
    "\n",
    "    #drop chrom column\n",
    "    test_set = test_set.drop(columns=['chrom'])\n",
    "    train_set = train_set.drop(columns=['chrom'])\n",
    "    data = data.drop(columns=['chrom'])\n",
    "\n",
    "    #seperate region_id column to combine at the end\n",
    "    test_regionid = test_set['region_id']\n",
    "    test_regionid = pd.DataFrame(test_regionid)\n",
    "    test_regionid = test_regionid.reset_index(drop=True)\n",
    "    test_regionid = test_regionid.sort_values(by=['region_id'])\n",
    "\n",
    "    #check correlation if you want\n",
    "#     sharpr_15_array = np.asarray(test_set['sharpr_15'])\n",
    "#     sharpr_15_array = sharpr_15_array.flatten()\n",
    "#     conv_15_array = np.asarray(conv_15)\n",
    "#     conv_15_array = conv_15_array.flatten()\n",
    "#     deepfact_15_array = np.asarray(deepfact_15)\n",
    "#     deepfact_15_array = deepfact_15_array.flatten()\n",
    "#     gkm_15_array = np.asarray(gkm_15)\n",
    "#     gkm_15_array = gkm_15_array.flatten()\n",
    "#     print('corr of Normalized (RNA/DNA) and dragoNN ConvModel:')\n",
    "#     print(pd.Series(sharpr_15_array).corr(pd.Series(conv_15_array),method='spearman'))\n",
    "#     print('corr of Normalized (RNA/DNA) and gkmSVMModel:')\n",
    "#     print(pd.Series(sharpr_15_array).corr(pd.Series(gkm_15_array),method='spearman'))\n",
    "#     print('corr of Normalized (RNA/DNA) and dragoNN DeepFactorizedModel:')\n",
    "#     print(pd.Series(sharpr_15_array).corr(pd.Series(deepfact_15_array),method='spearman'))\n",
    "\n",
    "    \n",
    "    #format training data\n",
    "    labels = train_set['sharpr_%s'%tile_num].values\n",
    "    train_set = train_set.drop(columns=['region_id','sharpr_%s'%tile_num])\n",
    "    encodings = train_set.values.tolist()\n",
    "    encodings = np.asarray(encodings)\n",
    "    encodings_df = pd.DataFrame(encodings)\n",
    "    encodings_df.fillna(encodings_df.mean(), inplace=True)\n",
    "    encodings = encodings_df.to_numpy()\n",
    "    labels = np.reshape(labels,(14753 ,))\n",
    "\n",
    "    #format the testing data\n",
    "    test_labels = test_set['sharpr_%s'%tile_num].values\n",
    "    test_set = test_set.drop(columns=['region_id','sharpr_%s'%tile_num])\n",
    "    test_encodings = test_set.values.tolist()\n",
    "    test_encodings = np.asarray(test_encodings)\n",
    "    test_encodings_df = pd.DataFrame(test_encodings)\n",
    "    test_encodings_df.fillna(test_encodings_df.mean(), inplace=True)\n",
    "    test_encodings = test_encodings_df.to_numpy()\n",
    "    test_labels = np.reshape(test_labels,(967 ,))\n",
    "\n",
    "\n",
    "    #format data\n",
    "    data_labels = data['sharpr_%s'%tile_num].values\n",
    "    data = data.drop(columns=['region_id','sharpr_%s'%tile_num])\n",
    "    data_encodings = data.values.tolist()\n",
    "    data_encodings = np.asarray(data_encodings)\n",
    "    data_encodings_df = pd.DataFrame(data_encodings)\n",
    "    data_encodings_df.fillna(data_encodings_df.mean(), inplace=True)\n",
    "    data_encodings = data_encodings_df.to_numpy()\n",
    "    data_labels = np.reshape(data_labels,(15720,))\n",
    "\n",
    "    #train a linear regressor on the training dataset. \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    sequence_regressor = LinearRegression()\n",
    "    sequence_regressor.fit(encodings, labels)\n",
    "    \n",
    "    \n",
    "    #save the regressor:\n",
    "    from sklearn.externals import joblib\n",
    "    path = '/u/home/m/mudiyang/scratch/Tile_Prediction_Regressors/Megan_Model/megan_t%s.pkl'%(tile_num+1)\n",
    "    joblib.dump(sequence_regressor, path)\n",
    "\n",
    "    #compute mse\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    train_predictions = sequence_regressor.predict(encodings)\n",
    "    train_mse = mean_squared_error(train_predictions, labels)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    print(\"root mean squared error = %s\"%train_rmse)\n",
    "\n",
    "    test_predictions = sequence_regressor.predict(test_encodings)\n",
    "    test_mse = mean_squared_error(test_predictions, test_labels)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #visualize the results\n",
    "    corr = pd.Series(test_predictions).corr(pd.Series(test_labels))\n",
    "\n",
    "    caption = \"correlation pearson r= %s\"%(corr)\n",
    "    rmse = \"root mean squared error = %s\"%test_rmse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     plt.scatter(\n",
    "#         x=test_predictions,\n",
    "#         y=test_labels,\n",
    "#         edgecolors='w'\n",
    "#     )\n",
    "#     tile_num = int(tile_num)\n",
    "#     tile_num = tile_num + 1\n",
    "\n",
    "#     plt.title(\"Tile %s Sequence Regressor on chr8,chr18 Test Set\"%(tile_num))\n",
    "#     plt.xlabel(\"test_predictions \\n\\n %s \\n\\n %s\"%(caption,rmse))\n",
    "#     plt.ylabel(\"test_labels\")\n",
    "\n",
    "#     plt.savefig(\"sequence_predictions_tile%s\"%tile_num)\n",
    "\n",
    "#     print(\"Regressor coefficients(ConvModel,gkmSVMModel,DeepFactorizedModel):\")\n",
    "#     print(sequence_regressor.coef_)\n",
    "\n",
    "    #format data\n",
    "    test_predictions = pd.DataFrame(test_predictions)\n",
    "    test_predictions = pd.concat([test_predictions,test_regionid], axis=1)\n",
    "    test_predictions = test_predictions.set_index('region_id')\n",
    "    test_labels = pd.DataFrame(test_labels)\n",
    "    test_labels = pd.concat([test_labels,test_regionid], axis=1)\n",
    "    test_labels = test_labels.set_index('region_id')\n",
    "    return test_predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions_df = pd.DataFrame()\n",
    "for tile in range(31):\n",
    "    tile_num = str(tile)\n",
    "    tile_df = sequence_file(tile_num)\n",
    "    tile_num = int(tile_num)\n",
    "    real_tile_num = tile_num+1\n",
    "    tile_df = tile_df.rename(columns={0:real_tile_num})\n",
    "    predictions_df = pd.concat([predictions_df,tile_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df.to_csv('/u/home/m/mudiyang/scratch/test/values.tsv', sep = '\\t', header = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
